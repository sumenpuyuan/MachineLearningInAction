{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据，从文本中构建向量 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['him', 'so', 'posting', 'stop', 'ate', 'flea', 'to', 'quit', 'food', 'park', 'my', 'dog', 'not', 'cute', 'has', 'worthless', 'is', 'licks', 'maybe', 'buyiing', 'mr', 'help', 'how', 'I', 'dalmation', 'take', 'please', 'steak', 'grabage', 'stupid', 'problem', 'love']\n"
     ]
    }
   ],
   "source": [
    "#词到向量的转换函数\n",
    "def loadDataSet():\n",
    "    postingList=[\n",
    "        ['my','dog','has','flea','problem','help','please'],\n",
    "        ['maybe','not','take','him','to','dog','park','stupid'],\n",
    "        ['my','dalmation','is','so','cute','I','love','him'],\n",
    "        ['stop','posting','stupid','worthless','grabage'],\n",
    "        ['mr','licks','ate','my','steak','how','to','stop','him'],\n",
    "        ['quit','buyiing','worthless','dog','food','stupid']\n",
    "    ]\n",
    "    classVec=[0,1,0,1,0,1]#1表示侮辱性文字 0表示正常文字\n",
    "    return postingList,classVec\n",
    "#生成不重复的单词\n",
    "def createVocabList(dataSet):\n",
    "    vocabSet=set([])\n",
    "    #合并\n",
    "    for document in dataSet:\n",
    "        vocabSet=vocabSet | set(document)\n",
    "    return list(vocabSet)\n",
    "def setOfWords2Vec(vocabList,inputSet):\n",
    "    returnVec=[0]*len(vocabList)#生成全是0 长度为字典长度的字典\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)]=1\n",
    "        else:\n",
    "            print('the word %s is not in my vocabulary'%(word))\n",
    "    return returnVec\n",
    "listOPosts,listClasses=loadDataSet()\n",
    "myVocabList=createVocabList(listOPosts)\n",
    "print(myVocabList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setOfWords2Vec(myVocabList,listOPosts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练算法，从词向量到计算概率 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "#朴素贝叶斯分类训练函数\n",
    "def trainNB0(trainMatrix,trainCategory):\n",
    "    numTrainDocs=len(trainMatrix)\n",
    "    numWords=len(trainMatrix[0])\n",
    "    pAbusive=sum(trainCategory)/float(numTrainDocs)\n",
    "    p0Num=zeros(numWords)\n",
    "    p1Num=zeros(numWords)\n",
    "    p0Denom=0.0\n",
    "    p1Denom=0.0\n",
    "    for i in range(numTrainDocs):\n",
    "        if trainCategory[i]==1:\n",
    "            p1Num+=trainMatrix[i]\n",
    "            p1Denom+=sum(trainMatrix[i])\n",
    "        else:\n",
    "            p0Num+=trainMatrix[i]\n",
    "            p0Denom+=sum(trainMatrix[i])\n",
    "    p1Vect=p1Num/p1Denom\n",
    "    p0Vect=p0Num/p0Denom\n",
    "    return p0Vect,p1Vect,pAbusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[0.08333333 0.04166667 0.         0.04166667 0.04166667 0.04166667\n",
      " 0.04166667 0.         0.         0.         0.125      0.04166667\n",
      " 0.         0.04166667 0.04166667 0.         0.04166667 0.04166667\n",
      " 0.         0.         0.04166667 0.04166667 0.04166667 0.04166667\n",
      " 0.04166667 0.         0.04166667 0.04166667 0.         0.\n",
      " 0.04166667 0.04166667]\n",
      "[0.05263158 0.         0.05263158 0.05263158 0.         0.\n",
      " 0.05263158 0.05263158 0.05263158 0.05263158 0.         0.10526316\n",
      " 0.05263158 0.         0.         0.10526316 0.         0.\n",
      " 0.05263158 0.05263158 0.         0.         0.         0.\n",
      " 0.         0.05263158 0.         0.         0.05263158 0.15789474\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "trainMat=[]\n",
    "for postinDoc in listOPosts:\n",
    "    trainMat.append(setOfWords2Vec(myVocabList,postinDoc))\n",
    "p0V,p1V,pAb=trainNB0(trainMat,listClasses)\n",
    "print(pAb)\n",
    "print(p0V)\n",
    "print(p1V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试算法：根据现实情况修改分类器 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.极大似然估计，出现0抹去的情况，使用拉普拉斯修正 ###\n",
    "### 2.连续相乘导致下溢 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainNB0(trainMatrix,trainCategory):\n",
    "    numTrainDocs=len(trainMatrix)\n",
    "    numWords=len(trainMatrix[0])\n",
    "    pAbusive=sum(trainCategory)/float(numTrainDocs)\n",
    "    #使用拉普拉斯修正\n",
    "    p0Num=ones(numWords)\n",
    "    p1Num=ones(numWords)\n",
    "    p0Denom=2.0\n",
    "    p1Denom=2.0\n",
    "    for i in range(numTrainDocs):\n",
    "        if trainCategory[i]==1:\n",
    "            p1Num+=trainMatrix[i]\n",
    "            p1Denom+=sum(trainMatrix[i])\n",
    "        else:\n",
    "            p0Num+=trainMatrix[i]\n",
    "            p0Denom+=sum(trainMatrix[i])\n",
    "    #使用对数防止下溢\n",
    "    p1Vect=log(p1Num/p1Denom)\n",
    "    p0Vect=log(p0Num/p0Denom)\n",
    "    return p0Vect,p1Vect,pAbusive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯分类函数 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['love', 'my', 'dalmation'] classifyed as :  0\n",
      "the word garbage is not in my vocabulary\n",
      "['stupid', 'garbage'] classified as :  1\n"
     ]
    }
   ],
   "source": [
    "def classifyNB(vec2Classify,p0Vec,p1Vec,pClass1):\n",
    "    p1=sum(vec2Classify*p1Vec)+log(pClass1)\n",
    "    p0=sum(vec2Classify*p0Vec)+log(1.0-pClass1)\n",
    "    if p1>p0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def testingNB():\n",
    "    listOPosts,listClasses=loadDataSet()\n",
    "    myVocabList=createVocabList(listOPosts)\n",
    "    trainMat=[]\n",
    "    for postinDoc in listOPosts:\n",
    "        trainMat.append(setOfWords2Vec(myVocabList,postinDoc))\n",
    "    p0V,p1V,pAb=trainNB0(trainMat,listClasses)\n",
    "    testEntry=['love','my','dalmation']\n",
    "    thisDoc=array(setOfWords2Vec(myVocabList,testEntry))\n",
    "    print(testEntry,'classifyed as : ',classifyNB(thisDoc,p0V,p1V,pAb))\n",
    "    testEntry=['stupid','garbage']\n",
    "    thisDoc=array(setOfWords2Vec(myVocabList,testEntry))\n",
    "    print(testEntry,'classified as : ',classifyNB(thisDoc,p0V,p1V,pAb))\n",
    "testingNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  朴素贝叶斯词袋模型 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bagOfWords2VecMN(vocabList,inputSet):\n",
    "    returnVec=[0]*len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)]+=1\n",
    "    return returnVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 示例：使用朴素贝叶斯过滤垃圾邮件 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'book',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'book',\n",
       " 'on',\n",
       " 'python',\n",
       " 'or',\n",
       " 'M.L',\n",
       " 'i',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'laid',\n",
       " 'eyes',\n",
       " 'upon']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mySent='this book is the best book on python or M.L i have ever laid eyes upon'\n",
    "mySent.split()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，切分效果不错，但是标点符号也被当成了词的一部分，可以用正则表示来切分句子，其中分隔符是除单词，数字外的任意字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: split() requires a non-empty pattern match.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'book',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'book',\n",
       " 'on',\n",
       " 'python',\n",
       " 'or',\n",
       " 'M',\n",
       " 'L',\n",
       " 'i',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'laid',\n",
       " 'eyes',\n",
       " 'upon']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "regEx=re.compile('\\\\W*')\n",
    "listOfTokens=regEx.split(mySent)\n",
    "listOfTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'book',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'book',\n",
       " 'on',\n",
       " 'python',\n",
       " 'or',\n",
       " 'm',\n",
       " 'l',\n",
       " 'i',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'laid',\n",
       " 'eyes',\n",
       " 'upon']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tok.lower() for tok in listOfTokens if(len(tok)>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: split() requires a non-empty pattern match.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "emailText=open('email/ham/6.txt').read()\n",
    "listOfTokens=regEx.split(emailText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试：使用朴素贝叶斯进行交叉验证 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textParse(bigString):    #input is big string, #output is word list\n",
    "    import re\n",
    "    listOfTokens = re.split(r'\\W*', bigString)\n",
    "    return [tok.lower() for tok in listOfTokens if len(tok) > 2] \n",
    "def spamTest():\n",
    "    docList=[]; classList = []; fullText =[]\n",
    "    for i in range(1,26):\n",
    "        wordList = textParse(open('email/spam/%d.txt' % i).read())\n",
    "        docList.append(wordList)\n",
    "        fullText.extend(wordList)\n",
    "        classList.append(1)\n",
    "        wordList = textParse(open('email/ham/%d.txt' % i).read())\n",
    "        docList.append(wordList)\n",
    "        fullText.extend(wordList)\n",
    "        classList.append(0)\n",
    "    vocabList = createVocabList(docList)#create vocabulary\n",
    "    trainingSet = list(range(50)); testSet=[]           #create test set\n",
    "    for i in range(10):\n",
    "        randIndex = int(random.uniform(0,len(trainingSet)))\n",
    "        testSet.append(trainingSet[randIndex])\n",
    "        del(trainingSet[randIndex])  \n",
    "    trainMat=[]; trainClasses = []\n",
    "    for docIndex in trainingSet:#train the classifier (get probs) trainNB0\n",
    "        trainMat.append(bagOfWords2VecMN(vocabList, docList[docIndex]))\n",
    "        trainClasses.append(classList[docIndex])\n",
    "    p0V,p1V,pSpam = trainNB0(array(trainMat),array(trainClasses))\n",
    "    errorCount = 0\n",
    "    for docIndex in testSet:        #classify the remaining items\n",
    "        wordVector = bagOfWords2VecMN(vocabList, docList[docIndex])\n",
    "        if classifyNB(array(wordVector),p0V,p1V,pSpam) != classList[docIndex]:\n",
    "            errorCount += 1\n",
    "            print (\"classification error\",docList[docIndex])\n",
    "    print ('the error rate is: ',float(errorCount)/len(testSet))\n",
    "    #return vocabList,fullText\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification error ['yay', 'you', 'both', 'doing', 'fine', 'working', 'mba', 'design', 'strategy', 'cca', 'top', 'art', 'school', 'new', 'program', 'focusing', 'more', 'right', 'brained', 'creative', 'and', 'strategic', 'approach', 'management', 'the', 'way', 'done', 'today']\n",
      "classification error ['yeah', 'ready', 'may', 'not', 'here', 'because', 'jar', 'jar', 'has', 'plane', 'tickets', 'germany', 'for']\n",
      "the error rate is:  0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "spamTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 使用朴素贝叶斯分类器从个人广告 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcMostFreq(vocabList,fullText):\n",
    "    import operator\n",
    "    freqDict = {}\n",
    "    for token in vocabList:\n",
    "        freqDict[token]=fullText.count(token)\n",
    "    sortedFreq = sorted(freqDict.items(), key=operator.itemgetter(1), reverse=True) \n",
    "    return sortedFreq[:30]       \n",
    "\n",
    "def localWords(feed1,feed0):\n",
    "    import feedparser\n",
    "    docList=[]; classList = []; fullText =[]\n",
    "    print(len(feed1['entries']))\n",
    "    print(len(feed0['entries']))\n",
    "    minLen = min(len(feed1['entries']),len(feed0['entries']))\n",
    "    for i in range(minLen):\n",
    "        wordList = textParse(feed1['entries'][i]['summary'])\n",
    "        docList.append(wordList)\n",
    "        fullText.extend(wordList)\n",
    "        classList.append(1) #NY is class 1\n",
    "        wordList = textParse(feed0['entries'][i]['summary'])\n",
    "        docList.append(wordList)\n",
    "        fullText.extend(wordList)\n",
    "        classList.append(0)\n",
    "    vocabList = createVocabList(docList)#create vocabulary\n",
    "    top30Words = calcMostFreq(vocabList,fullText)   #remove top 30 words\n",
    "    for pairW in top30Words:\n",
    "        if pairW[0] in vocabList: vocabList.remove(pairW[0])\n",
    "    trainingSet = list(range(2*minLen)); testSet=[]           #create test set\n",
    "    for i in range(20):\n",
    "        randIndex = int(random.uniform(0,len(trainingSet)))\n",
    "        testSet.append(trainingSet[randIndex])\n",
    "        del(trainingSet[randIndex])  \n",
    "    trainMat=[]; trainClasses = []\n",
    "    for docIndex in trainingSet:#train the classifier (get probs) trainNB0\n",
    "        trainMat.append(bagOfWords2VecMN(vocabList, docList[docIndex]))\n",
    "        trainClasses.append(classList[docIndex])\n",
    "    p0V,p1V,pSpam = trainNB0(array(trainMat),array(trainClasses))\n",
    "    errorCount = 0\n",
    "    for docIndex in testSet:        #classify the remaining items\n",
    "        wordVector = bagOfWords2VecMN(vocabList, docList[docIndex])\n",
    "        if classifyNB(array(wordVector),p0V,p1V,pSpam) != classList[docIndex]:\n",
    "            errorCount += 1\n",
    "    print('the error rate is: ',float(errorCount)/len(testSet))\n",
    "    return vocabList,p0V,p1V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "30\n",
      "the error rate is:  0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "# ny = feedparser.parse('http://newyork.craigslist.org/stp/index.rss')\n",
    "# sf = feedparser.parse('http://sfbay.craigslist.org/stp/index.rss')\n",
    "ny = feedparser.parse('http://www.nasa.gov/rss/dyn/image_of_the_day.rss')\n",
    "sf = feedparser.parse('http://rss.yule.sohu.com/rss/yuletoutiao.xml')\n",
    "vocabList, pSF, pNY = localWords(ny, sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTopWords(ny,sf):\n",
    "    import operator\n",
    "    vocabList,p0V,p1V=localWords(ny,sf)\n",
    "    topNY=[]; topSF=[]\n",
    "    for i in range(len(p0V)):\n",
    "        if p0V[i] > -6.0 : topSF.append((vocabList[i],p0V[i]))\n",
    "        if p1V[i] > -6.0 : topNY.append((vocabList[i],p1V[i]))\n",
    "    sortedSF = sorted(topSF, key=lambda pair: pair[1], reverse=True)\n",
    "    print(\"SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**\")\n",
    "    for item in sortedSF:\n",
    "        print(item[0])\n",
    "    sortedNY = sorted(topNY, key=lambda pair: pair[1], reverse=True)\n",
    "    print(\"NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**\")\n",
    "    for item in sortedNY:\n",
    "        print(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "30\n",
      "the error rate is:  0.5\n",
      "SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**\n",
      "据香港媒体报道\n",
      "小海绵\n",
      "据台湾媒体报道\n",
      "假张译微信招表演学生\n",
      "我不是潘金莲\n",
      "有网友拍到白百何带儿子现身上海大悦城\n",
      "高晓松在京出席某地图发布会\n",
      "胡海泉否认羽泉解散\n",
      "他果断否认羽泉解散\n",
      "购入浅水湾道低密度住宅怡峰一个望海景单位\n",
      "由范冰冰主演\n",
      "张译发文辟谣做导演教学生\n",
      "现场他被聘为首席采集娱乐官\n",
      "白百何头戴鸭舌帽\n",
      "乒乓王子\n",
      "突然被莫明伤害到的人物应该给他很多空间\n",
      "孔令辉的国家女乒帅位已经由同僚李隼代替\n",
      "根据孩子的背影与身\n",
      "张译曝光骗子以他名义冒充副导演和网友聊天截\n",
      "伊能静在文中解释道\n",
      "只是角度选择的问题\n",
      "艺人杨颖\n",
      "一直都专心照顾孩子\n",
      "秦昊微博截图\n",
      "被送到医院抢救仍宣告不治\n",
      "乔欣说自己还有个姐姐\n",
      "跨界上演了一部\n",
      "被问及近期陈羽凡因婚变宣布无限期离开娱乐圈一事\n",
      "他笑说\n",
      "直挺挺地倒下\n",
      "前一秒还拿麦克风唱着歌\n",
      "高育良\n",
      "张凯丽在微博晒和\n",
      "做什么事儿\n",
      "angelababy\n",
      "金沙的代表律师已经向香港高等法院提出终止法律程序\n",
      "海外在娱乐方面的投资是赚钱\n",
      "就该脚踏实地的努\n",
      "被怀疑从头到尾都是自导自演\n",
      "张智霖谈做郭富城伴郎感受\n",
      "我不是一个电影制片人\n",
      "羽泉当然存在啊\n",
      "由后者带领中国女队出战世界乒乓球锦标赛\n",
      "潘金莲是不正经的女\n",
      "中国女乒队前主教练\n",
      "活地图\n",
      "全剧最期待的对手戏\n",
      "艺人张智霖\n",
      "他每年只和母亲一起去看电影一次\n",
      "身穿白色上衣\n",
      "向来孝顺的谢霆锋今年的父亲节礼物特别大份\n",
      "孔令辉的欠债风波又有新进展\n",
      "我们每\n",
      "他倒下的瞬间影片在25日曝光\n",
      "高晓松发言\n",
      "并首度自曝家庭情况\n",
      "谈到对于二胎的看法\n",
      "和她们合照压力好大\n",
      "我们要给在乎的人空间和包容\n",
      "西里_cili\n",
      "需要理解\n",
      "问他到那他的太太袁咏仪呢\n",
      "简直就是中国版的无间道夫妇\n",
      "4月20日\n",
      "一旁的乔欣连忙接话\n",
      "冯小刚2016年上映的电影\n",
      "有网友爆料白百何携子现身上海大悦城\n",
      "4月17日晚\n",
      "人民的名义\n",
      "4月18日晚\n",
      "伊能静在微博发长文为老公秦昊在节目中被黑喊冤\n",
      "实用尺价约4\n",
      "资深港星曾守明23日在广州表演\n",
      "采访时认为\n",
      "张凯丽在微\n",
      "唐禹哲发文否认恋网红\n",
      "金融时报\n",
      "25日\n",
      "但女方随后遭到网友起底\n",
      "38万港币\n",
      "chilam\n",
      "一名助理指出\n",
      "胡海泉在参加活动时\n",
      "未料唱歌唱到一半突然昏倒\n",
      "那她一定觉得很幸福\n",
      "为两房两厅连一个套房间格\n",
      "中因称\n",
      "金牌绿叶曾守明演出中途暴毙最后画面曝光\n",
      "黄晓明baby和小海绵\n",
      "他帮米粒换尿布\n",
      "两位都是殿堂级美女\n",
      "他甚至没有看去年的电影\n",
      "张志坚携真媳妇请张凯丽吃饭\n",
      "觉得姐姐是上天安排的礼物\n",
      "想红想博得关注\n",
      "张科明\n",
      "王健林表示\n",
      "情侣合照\n",
      "而另一张照片里\n",
      "称跟网友无关\n",
      "让现场所有观众吓呆了\n",
      "中吴老师的扮演者张凯丽和张志坚扮演的高育良的对手戏也被网友称赞为\n",
      "以8500万港元\n",
      "艺人唐禹哲被爆热恋大陆网红\n",
      "约合人民币7430万元\n",
      "还有一个比他小18岁的妹妹\n",
      "一天24小时拍摄\n",
      "孔令辉成功找到友人与新加坡滨海湾金沙娱乐城交涉\n",
      "黄静圯\n",
      "联合早报\n",
      "孝顺儿女都会花心思送礼报恩\n",
      "胡海泉还表示了对羽凡的力挺\n",
      "太阳宫\n",
      "被集中在一起\n",
      "不过都是见到小宝宝的头和手\n",
      "自己的哥哥是个这么大的明星\n",
      "文章来源\n",
      "在节目环节中\n",
      "于年初为老公黄晓明诞下\n",
      "据网友拍摄的照片来看\n",
      "唐禹哲20日也亲自出面\n",
      "王健林近日在接受英国\n",
      "疑似自行ps合成\n",
      "一次过清还所有欠款\n",
      "他接受访问时自曝二人都是他的女神\n",
      "82万元\n",
      "白百何身边还站着一个小男孩\n",
      "神色如常地玩手机\n",
      "王健林\n",
      "李晨在某综艺节目中谈及对孩子的看法\n",
      "我是一家电影公司的商人\n",
      "之前她就带着\n",
      "父亲节将至\n",
      "玄反影\n",
      "秦先生只有一小时玩游戏\n",
      "他回说\n",
      "下一秒突然就一阵摇晃\n",
      "向西里_cili喊话\n",
      "享年56岁\n",
      "杨丽萍与村民们\n",
      "亮相自己有份参加的真人秀\n",
      "约合人民币3\n",
      "出席活动\n",
      "送给80岁的谢贤\n",
      "奔跑吧兄弟\n",
      "是代表香港的女神\n",
      "除了几位工作人员的陪伴\n",
      "与同场的女星钟楚红及关之琳合照\n",
      "李晨坦言自己父母离异\n",
      "土地注\n",
      "false\n",
      "composite\n",
      "只要贾静雯喜欢都可以\n",
      "october\n",
      "round\n",
      "california\n",
      "student\n",
      "dark\n",
      "floating\n",
      "called\n",
      "shipment\n",
      "ethereal\n",
      "retriever\n",
      "collecting\n",
      "五月底\n",
      "night\n",
      "commercial\n",
      "nov\n",
      "arrived\n",
      "ellen\n",
      "orbit\n",
      "into\n",
      "land\n",
      "身携时下最流行的ip和偶像双重光环\n",
      "vehicle\n",
      "fog\n",
      "眼神就怪怪的\n",
      "launching\n",
      "contributions\n",
      "方媛在instagram秒删的两张图片\n",
      "1998\n",
      "贾静雯刚做完月子\n",
      "but\n",
      "revolution\n",
      "terrain\n",
      "installs\n",
      "feustel\n",
      "years\n",
      "他霸气说\n",
      "神奇女侠\n",
      "1962\n",
      "texas\n",
      "black\n",
      "works\n",
      "features\n",
      "where\n",
      "its\n",
      "european\n",
      "pad\n",
      "张译在微博中发表长文回应此\n",
      "star\n",
      "加勒比海盗5\n",
      "japanese\n",
      "9th\n",
      "对此top正在服兵役的首尔地方警察厅宣传部门负责人表示将根据检察院调查结果处罚top\n",
      "even\n",
      "photographed\n",
      "northern\n",
      "imager\n",
      "water\n",
      "的开播可谓是声势浩大\n",
      "gulf\n",
      "修杰楷\n",
      "landing\n",
      "张译自曝曾把女孩塞进水缸中\n",
      "delivered\n",
      "的视频\n",
      "families\n",
      "commander\n",
      "autumn\n",
      "murtha\n",
      "three\n",
      "per\n",
      "曾舜晞\n",
      "sea\n",
      "aboard\n",
      "test\n",
      "one\n",
      "perform\n",
      "used\n",
      "韩国偶像组合bigbang成员top今天被爆料违法吸食大麻\n",
      "有网友扒出张译在2013年参加\n",
      "oleg\n",
      "cunningham\n",
      "择天记\n",
      "drifts\n",
      "suwannee\n",
      "但是周董最近都火到国际上了\n",
      "宣告了暑期档提前到来\n",
      "airglow\n",
      "service\n",
      "glittering\n",
      "tuesday\n",
      "launch\n",
      "ago\n",
      "只见方媛晒出一张自己做菜的照片\n",
      "might\n",
      "his\n",
      "agency\n",
      "onboard\n",
      "1989\n",
      "footprint\n",
      "kennedy\n",
      "along\n",
      "center\n",
      "ovchinin\n",
      "been\n",
      "top涉嫌去年10月在首尔自己家与一名女性友人吸食大麻一共三次\n",
      "team\n",
      "nueces\n",
      "material\n",
      "foot\n",
      "妖精会\n",
      "feb\n",
      "demonstrate\n",
      "mexico\n",
      "他笑言\n",
      "down\n",
      "served\n",
      "poses\n",
      "region\n",
      "flowing\n",
      "非常静距离\n",
      "dusty\n",
      "视频中\n",
      "create\n",
      "because\n",
      "blackwater\n",
      "curling\n",
      "秦舒培晒照毫无孕相\n",
      "张译录制节目称成立\n",
      "最近英国一家媒体对周董是大加赞赏\n",
      "astronauts\n",
      "hemisphere\n",
      "around\n",
      "remind\n",
      "roscosmos\n",
      "heritage\n",
      "most\n",
      "becoming\n",
      "4月24日\n",
      "validate\n",
      "training\n",
      "second\n",
      "媒体问他\n",
      "viewed\n",
      "procedures\n",
      "our\n",
      "side\n",
      "acaba\n",
      "not\n",
      "month\n",
      "cupola\n",
      "john\n",
      "will\n",
      "parker\n",
      "又是作为粉丝量巨大的年轻偶像鹿晗首度出演的电视剧\n",
      "donn\n",
      "krayniy\n",
      "areas\n",
      "有时甚至半夜爬起来给自己做\n",
      "国产电影只能在\n",
      "ricky\n",
      "gravity\n",
      "splashes\n",
      "national\n",
      "miles\n",
      "botany\n",
      "always\n",
      "crews\n",
      "apparitions\n",
      "周杰伦\n",
      "time\n",
      "flight\n",
      "邓紫棋和一位穿白色衣服的男子牵\n",
      "investigators\n",
      "4月19日\n",
      "recovered\n",
      "feline\n",
      "schirra\n",
      "series\n",
      "连微博前几天晒的三菜一汤厨艺照也都删了\n",
      "fuel\n",
      "paw\n",
      "former\n",
      "toward\n",
      "eisele\n",
      "400\n",
      "using\n",
      "telescope\n",
      "object\n",
      "nine\n",
      "张译回忆起自己早年在剧组欺负女性工作人员的事\n",
      "ochoa\n",
      "aug\n",
      "tests\n",
      "sept\n",
      "cygnus\n",
      "science\n",
      "professionals\n",
      "sky\n",
      "artist\n",
      "data\n",
      "such\n",
      "oli\n",
      "贾静雯\n",
      "outer\n",
      "荤素搭配\n",
      "mountainous\n",
      "而对top进行的毛发检测结果也\n",
      "transfer\n",
      "有没有要\n",
      "deployed\n",
      "刚刚出门的时候她\n",
      "michael\n",
      "taken\n",
      "有网友爆料在日本涉谷的街头遇到了邓紫棋\n",
      "drew\n",
      "jupiter\n",
      "operational\n",
      "18th\n",
      "alexey\n",
      "living\n",
      "snow\n",
      "storms\n",
      "their\n",
      "修杰楷出席活动\n",
      "named\n",
      "are\n",
      "atlantis\n",
      "kepler\n",
      "bright\n",
      "flooding\n",
      "reading\n",
      "further\n",
      "amounts\n",
      "women\n",
      "变形金刚5\n",
      "reported\n",
      "day\n",
      "assist\n",
      "planets\n",
      "立即引发网友不满\n",
      "媒体接着追问打算买什么礼物给贾静雯\n",
      "既是知名网文作家猫腻点击量相当高的ip作品\n",
      "英国telegrap\n",
      "achievements\n",
      "ocean\n",
      "designed\n",
      "probe\n",
      "embrace\n",
      "birthday\n",
      "teacher\n",
      "rolled\n",
      "river\n",
      "people\n",
      "arnold\n",
      "cat\n",
      "located\n",
      "nick\n",
      "dnieper\n",
      "set\n",
      "mile\n",
      "southern\n",
      "cloud\n",
      "humans\n",
      "walter\n",
      "milky\n",
      "russia\n",
      "men\n",
      "该视频被爆出后\n",
      "recover\n",
      "have\n",
      "color\n",
      "neutral\n",
      "buoyancy\n",
      "sun\n",
      "scorpius\n",
      "gemini\n",
      "gear\n",
      "enveloped\n",
      "globular\n",
      "据首尔地方警察厅毒品犯罪搜查队透露\n",
      "torus\n",
      "out\n",
      "eight\n",
      "launched\n",
      "revealed\n",
      "那预算呢\n",
      "needed\n",
      "照片中有七菜一汤\n",
      "more\n",
      "搜狐娱乐独家专稿\n",
      "returned\n",
      "rocket\n",
      "giant\n",
      "paranormal\n",
      "minutes\n",
      "verify\n",
      "splashed\n",
      "pacific\n",
      "acronym\n",
      "silhouette\n",
      "虽然放在湖南卫视的周\n",
      "since\n",
      "impression\n",
      "better\n",
      "cosmonaut\n",
      "母亲节也即将来临\n",
      "外媒评价周杰伦为\n",
      "soyuz\n",
      "central\n",
      "upside\n",
      "surroundings\n",
      "waters\n",
      "brilliant\n",
      "glow\n",
      "large\n",
      "brown\n",
      "artemyev\n",
      "solar\n",
      "shaped\n",
      "window\n",
      "planet\n",
      "transits\n",
      "成了网友热议的焦点\n",
      "experiment\n",
      "module\n",
      "was\n",
      "galileo\n",
      "rain\n",
      "survival\n",
      "work\n",
      "glenn\n",
      "right\n",
      "five\n",
      "4月18日\n",
      "2017年6月将在内地公映的影片\n",
      "undocking\n",
      "shuttle\n",
      "ngc\n",
      "billions\n",
      "新木乃伊\n",
      "captured\n",
      "cluster\n",
      "checklist\n",
      "how\n",
      "veggie\n",
      "preparations\n",
      "uss\n",
      "gas\n",
      "missions\n",
      "方媛其实很爱做饭\n",
      "following\n",
      "facility\n",
      "lands\n",
      "hague\n",
      "spent\n",
      "train\n",
      "cassieopeia\n",
      "sunset\n",
      "stars\n",
      "world\n",
      "members\n",
      "于将于今晚\n",
      "core\n",
      "港星陈冠希1月被爆与女友秦舒培已经有爱的结晶\n",
      "preparation\n",
      "many\n",
      "other\n",
      "修杰楷表示\n",
      "capsule\n",
      "nanoracks\n",
      "张译让剧组女生下跪\n",
      "邓紫棋和白衣男子牵手逛街\n",
      "laden\n",
      "left\n",
      "sunday\n",
      "还逼迫女生下跪加入自己的帮会\n",
      "those\n",
      "known\n",
      "orion\n",
      "donut\n",
      "which\n",
      "discovery\n",
      "another\n",
      "sped\n",
      "magnified\n",
      "deep\n",
      "constellation\n",
      "inside\n",
      "shows\n",
      "gerst\n",
      "awakening\n",
      "aeronautics\n",
      "growth\n",
      "version\n",
      "visible\n",
      "may\n",
      "alexander\n",
      "organic\n",
      "nebula\n",
      "than\n",
      "means\n",
      "陈数等领衔主演的古装玄幻大剧\n",
      "等好莱坞大片把一整个月占得满满当当\n",
      "body\n",
      "run\n",
      "1898\n",
      "forming\n",
      "2017\n",
      "jets\n",
      "magellanic\n",
      "plant\n",
      "part\n",
      "operations\n",
      "由鹿晗\n",
      "hardware\n",
      "filled\n",
      "galaxy\n",
      "six\n",
      "hours\n",
      "exploration\n",
      "laboratory\n",
      "conception\n",
      "joe\n",
      "happy\n",
      "valleys\n",
      "airport\n",
      "lies\n",
      "而且预产期\n",
      "command\n",
      "celestial\n",
      "中求生存\n",
      "landsat\n",
      "historic\n",
      "celebrating\n",
      "ghost\n",
      "egress\n",
      "roughly\n",
      "spitzer\n",
      "senator\n",
      "hidden\n",
      "周杰伦的音乐才华我们已经不用多说\n",
      "practiced\n",
      "华人之光\n",
      "airbus\n",
      "home\n",
      "pilot\n",
      "venus\n",
      "collins\n",
      "december\n",
      "这张照片随后被方媛秒删\n",
      "ball\n",
      "has\n",
      "1995\n",
      "fire\n",
      "暑期档正式开启第一波鏖战\n",
      "expedition\n",
      "way\n",
      "应该都是郭富城爱吃的\n",
      "NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**\n",
      "pilot\n",
      "has\n",
      "october\n",
      "nov\n",
      "years\n",
      "water\n",
      "gulf\n",
      "aboard\n",
      "test\n",
      "mexico\n",
      "down\n",
      "procedures\n",
      "our\n",
      "john\n",
      "will\n",
      "time\n",
      "series\n",
      "toward\n",
      "science\n",
      "michael\n",
      "taken\n",
      "their\n",
      "planets\n",
      "ocean\n",
      "river\n",
      "people\n",
      "walter\n",
      "pacific\n",
      "was\n",
      "glenn\n",
      "right\n",
      "captured\n",
      "stars\n",
      "orion\n",
      "which\n",
      "deep\n",
      "than\n",
      "hardware\n",
      "filled\n",
      "senator\n",
      "collins\n",
      "false\n",
      "composite\n",
      "round\n",
      "california\n",
      "student\n",
      "dark\n",
      "ethereal\n",
      "retriever\n",
      "collecting\n",
      "night\n",
      "commercial\n",
      "land\n",
      "fog\n",
      "contributions\n",
      "1998\n",
      "revolution\n",
      "installs\n",
      "1962\n",
      "texas\n",
      "works\n",
      "where\n",
      "its\n",
      "even\n",
      "photographed\n",
      "northern\n",
      "imager\n",
      "landing\n",
      "delivered\n",
      "families\n",
      "commander\n",
      "autumn\n",
      "murtha\n",
      "three\n",
      "per\n",
      "one\n",
      "used\n",
      "cunningham\n",
      "suwannee\n",
      "airglow\n",
      "glittering\n",
      "ago\n",
      "might\n",
      "his\n",
      "agency\n",
      "onboard\n",
      "along\n",
      "center\n",
      "ovchinin\n",
      "been\n",
      "nueces\n",
      "material\n",
      "foot\n",
      "demonstrate\n",
      "served\n",
      "because\n",
      "blackwater\n",
      "hemisphere\n",
      "remind\n",
      "roscosmos\n",
      "heritage\n",
      "most\n",
      "validate\n",
      "training\n",
      "second\n",
      "side\n",
      "acaba\n",
      "month\n",
      "parker\n",
      "donn\n",
      "krayniy\n",
      "areas\n",
      "ricky\n",
      "gravity\n",
      "splashes\n",
      "national\n",
      "miles\n",
      "botany\n",
      "always\n",
      "apparitions\n",
      "flight\n",
      "investigators\n",
      "recovered\n",
      "schirra\n",
      "fuel\n",
      "former\n",
      "eisele\n",
      "using\n",
      "telescope\n",
      "object\n",
      "nine\n",
      "aug\n",
      "tests\n",
      "sept\n",
      "sky\n",
      "data\n",
      "such\n",
      "oli\n",
      "mountainous\n",
      "operational\n",
      "18th\n",
      "alexey\n",
      "living\n",
      "storms\n",
      "are\n",
      "kepler\n",
      "bright\n",
      "flooding\n",
      "further\n",
      "amounts\n",
      "women\n",
      "reported\n",
      "assist\n",
      "designed\n",
      "probe\n",
      "embrace\n",
      "birthday\n",
      "teacher\n",
      "arnold\n",
      "nick\n",
      "set\n",
      "southern\n",
      "cloud\n",
      "humans\n",
      "men\n",
      "recover\n",
      "have\n",
      "color\n",
      "neutral\n",
      "buoyancy\n",
      "sun\n",
      "gemini\n",
      "gear\n",
      "enveloped\n",
      "globular\n",
      "out\n",
      "launched\n",
      "revealed\n",
      "needed\n",
      "more\n",
      "returned\n",
      "paranormal\n",
      "verify\n",
      "splashed\n",
      "acronym\n",
      "silhouette\n",
      "since\n",
      "better\n",
      "cosmonaut\n",
      "soyuz\n",
      "central\n",
      "waters\n",
      "brilliant\n",
      "glow\n",
      "large\n",
      "brown\n",
      "solar\n",
      "planet\n",
      "transits\n",
      "experiment\n",
      "module\n",
      "rain\n",
      "survival\n",
      "five\n",
      "undocking\n",
      "shuttle\n",
      "ngc\n",
      "billions\n",
      "cluster\n",
      "veggie\n",
      "uss\n",
      "missions\n",
      "following\n",
      "facility\n",
      "hague\n",
      "cassieopeia\n",
      "sunset\n",
      "members\n",
      "preparation\n",
      "many\n",
      "capsule\n",
      "nanoracks\n",
      "laden\n",
      "left\n",
      "sunday\n",
      "those\n",
      "known\n",
      "discovery\n",
      "another\n",
      "sped\n",
      "shows\n",
      "gerst\n",
      "awakening\n",
      "aeronautics\n",
      "growth\n",
      "version\n",
      "visible\n",
      "alexander\n",
      "organic\n",
      "means\n",
      "body\n",
      "run\n",
      "1898\n",
      "magellanic\n",
      "plant\n",
      "part\n",
      "operations\n",
      "exploration\n",
      "laboratory\n",
      "joe\n",
      "happy\n",
      "valleys\n",
      "airport\n",
      "lies\n",
      "command\n",
      "celestial\n",
      "landsat\n",
      "historic\n",
      "celebrating\n",
      "ghost\n",
      "egress\n",
      "roughly\n",
      "hidden\n",
      "practiced\n",
      "home\n",
      "venus\n",
      "ball\n",
      "expedition\n",
      "胡海泉否认羽泉解散\n",
      "他果断否认羽泉解散\n",
      "购入浅水湾道低密度住宅怡峰一个望海景单位\n",
      "由范冰冰主演\n",
      "只要贾静雯喜欢都可以\n",
      "张译发文辟谣做导演教学生\n",
      "现场他被聘为首席采集娱乐官\n",
      "白百何头戴鸭舌帽\n",
      "floating\n",
      "乒乓王子\n",
      "called\n",
      "shipment\n",
      "突然被莫明伤害到的人物应该给他很多空间\n",
      "五月底\n",
      "孔令辉的国家女乒帅位已经由同僚李隼代替\n",
      "根据孩子的背影与身\n",
      "arrived\n",
      "张译曝光骗子以他名义冒充副导演和网友聊天截\n",
      "ellen\n",
      "orbit\n",
      "into\n",
      "伊能静在文中解释道\n",
      "身携时下最流行的ip和偶像双重光环\n",
      "vehicle\n",
      "只是角度选择的问题\n",
      "眼神就怪怪的\n",
      "launching\n",
      "艺人杨颖\n",
      "方媛在instagram秒删的两张图片\n",
      "贾静雯刚做完月子\n",
      "一直都专心照顾孩子\n",
      "but\n",
      "terrain\n",
      "feustel\n",
      "他霸气说\n",
      "秦昊微博截图\n",
      "神奇女侠\n",
      "被送到医院抢救仍宣告不治\n",
      "乔欣说自己还有个姐姐\n",
      "black\n",
      "features\n",
      "跨界上演了一部\n",
      "被问及近期陈羽凡因婚变宣布无限期离开娱乐圈一事\n",
      "european\n",
      "pad\n",
      "张译在微博中发表长文回应此\n",
      "star\n",
      "加勒比海盗5\n",
      "japanese\n",
      "9th\n",
      "他笑说\n",
      "对此top正在服兵役的首尔地方警察厅宣传部门负责人表示将根据检察院调查结果处罚top\n",
      "直挺挺地倒下\n",
      "前一秒还拿麦克风唱着歌\n",
      "的开播可谓是声势浩大\n",
      "高育良\n",
      "修杰楷\n",
      "张凯丽在微博晒和\n",
      "小海绵\n",
      "张译自曝曾把女孩塞进水缸中\n",
      "的视频\n",
      "做什么事儿\n",
      "angelababy\n",
      "金沙的代表律师已经向香港高等法院提出终止法律程序\n",
      "海外在娱乐方面的投资是赚钱\n",
      "曾舜晞\n",
      "sea\n",
      "就该脚踏实地的努\n",
      "被怀疑从头到尾都是自导自演\n",
      "张智霖谈做郭富城伴郎感受\n",
      "perform\n",
      "韩国偶像组合bigbang成员top今天被爆料违法吸食大麻\n",
      "有网友扒出张译在2013年参加\n",
      "我不是一个电影制片人\n",
      "羽泉当然存在啊\n",
      "据台湾媒体报道\n",
      "oleg\n",
      "由后者带领中国女队出战世界乒乓球锦标赛\n",
      "择天记\n",
      "drifts\n",
      "但是周董最近都火到国际上了\n",
      "宣告了暑期档提前到来\n",
      "service\n",
      "tuesday\n",
      "launch\n",
      "只见方媛晒出一张自己做菜的照片\n",
      "1989\n",
      "潘金莲是不正经的女\n",
      "footprint\n",
      "kennedy\n",
      "中国女乒队前主教练\n",
      "活地图\n",
      "全剧最期待的对手戏\n",
      "艺人张智霖\n",
      "他每年只和母亲一起去看电影一次\n",
      "top涉嫌去年10月在首尔自己家与一名女性友人吸食大麻一共三次\n",
      "team\n",
      "身穿白色上衣\n",
      "向来孝顺的谢霆锋今年的父亲节礼物特别大份\n",
      "妖精会\n",
      "feb\n",
      "孔令辉的欠债风波又有新进展\n",
      "他笑言\n",
      "我们每\n",
      "poses\n",
      "region\n",
      "他倒下的瞬间影片在25日曝光\n",
      "flowing\n",
      "非常静距离\n",
      "dusty\n",
      "视频中\n",
      "create\n",
      "高晓松发言\n",
      "并首度自曝家庭情况\n",
      "curling\n",
      "秦舒培晒照毫无孕相\n",
      "张译录制节目称成立\n",
      "谈到对于二胎的看法\n",
      "最近英国一家媒体对周董是大加赞赏\n",
      "astronauts\n",
      "around\n",
      "和她们合照压力好大\n",
      "becoming\n",
      "我们要给在乎的人空间和包容\n",
      "4月24日\n",
      "西里_cili\n",
      "需要理解\n",
      "问他到那他的太太袁咏仪呢\n",
      "媒体问他\n",
      "简直就是中国版的无间道夫妇\n",
      "viewed\n",
      "4月20日\n",
      "not\n",
      "一旁的乔欣连忙接话\n",
      "冯小刚2016年上映的电影\n",
      "cupola\n",
      "有网友爆料白百何携子现身上海大悦城\n",
      "又是作为粉丝量巨大的年轻偶像鹿晗首度出演的电视剧\n",
      "有时甚至半夜爬起来给自己做\n",
      "4月17日晚\n",
      "国产电影只能在\n",
      "人民的名义\n",
      "crews\n",
      "4月18日晚\n",
      "周杰伦\n",
      "伊能静在微博发长文为老公秦昊在节目中被黑喊冤\n",
      "实用尺价约4\n",
      "邓紫棋和一位穿白色衣服的男子牵\n",
      "4月19日\n",
      "feline\n",
      "资深港星曾守明23日在广州表演\n",
      "连微博前几天晒的三菜一汤厨艺照也都删了\n",
      "paw\n",
      "采访时认为\n",
      "400\n",
      "张凯丽在微\n",
      "张译回忆起自己早年在剧组欺负女性工作人员的事\n",
      "ochoa\n",
      "cygnus\n",
      "唐禹哲发文否认恋网红\n",
      "professionals\n",
      "artist\n",
      "贾静雯\n",
      "金融时报\n",
      "outer\n",
      "荤素搭配\n",
      "25日\n",
      "而对top进行的毛发检测结果也\n",
      "transfer\n",
      "有没有要\n",
      "deployed\n",
      "但女方随后遭到网友起底\n",
      "38万港币\n",
      "刚刚出门的时候她\n",
      "chilam\n",
      "有网友爆料在日本涉谷的街头遇到了邓紫棋\n",
      "一名助理指出\n",
      "drew\n",
      "jupiter\n",
      "胡海泉在参加活动时\n",
      "未料唱歌唱到一半突然昏倒\n",
      "snow\n",
      "那她一定觉得很幸福\n",
      "修杰楷出席活动\n",
      "named\n",
      "atlantis\n",
      "为两房两厅连一个套房间格\n",
      "reading\n",
      "中因称\n",
      "金牌绿叶曾守明演出中途暴毙最后画面曝光\n",
      "黄晓明baby和小海绵\n",
      "变形金刚5\n",
      "他帮米粒换尿布\n",
      "day\n",
      "两位都是殿堂级美女\n",
      "据香港媒体报道\n",
      "立即引发网友不满\n",
      "媒体接着追问打算买什么礼物给贾静雯\n",
      "既是知名网文作家猫腻点击量相当高的ip作品\n",
      "英国telegrap\n",
      "他甚至没有看去年的电影\n",
      "张志坚携真媳妇请张凯丽吃饭\n",
      "觉得姐姐是上天安排的礼物\n",
      "achievements\n",
      "rolled\n",
      "想红想博得关注\n",
      "张科明\n",
      "cat\n",
      "located\n",
      "dnieper\n",
      "王健林表示\n",
      "mile\n",
      "情侣合照\n",
      "而另一张照片里\n",
      "称跟网友无关\n",
      "milky\n",
      "russia\n",
      "假张译微信招表演学生\n",
      "该视频被爆出后\n",
      "让现场所有观众吓呆了\n",
      "中吴老师的扮演者张凯丽和张志坚扮演的高育良的对手戏也被网友称赞为\n",
      "以8500万港元\n",
      "scorpius\n",
      "艺人唐禹哲被爆热恋大陆网红\n",
      "约合人民币7430万元\n",
      "还有一个比他小18岁的妹妹\n",
      "据首尔地方警察厅毒品犯罪搜查队透露\n",
      "torus\n",
      "eight\n",
      "那预算呢\n",
      "一天24小时拍摄\n",
      "照片中有七菜一汤\n",
      "孔令辉成功找到友人与新加坡滨海湾金沙娱乐城交涉\n",
      "搜狐娱乐独家专稿\n",
      "黄静圯\n",
      "rocket\n",
      "giant\n",
      "联合早报\n",
      "minutes\n",
      "我不是潘金莲\n",
      "虽然放在湖南卫视的周\n",
      "孝顺儿女都会花心思送礼报恩\n",
      "impression\n",
      "母亲节也即将来临\n",
      "外媒评价周杰伦为\n",
      "胡海泉还表示了对羽凡的力挺\n",
      "太阳宫\n",
      "upside\n",
      "surroundings\n",
      "被集中在一起\n",
      "artemyev\n",
      "shaped\n",
      "window\n",
      "成了网友热议的焦点\n",
      "galileo\n",
      "work\n",
      "4月18日\n",
      "2017年6月将在内地公映的影片\n",
      "新木乃伊\n",
      "不过都是见到小宝宝的头和手\n",
      "自己的哥哥是个这么大的明星\n",
      "checklist\n",
      "how\n",
      "preparations\n",
      "gas\n",
      "方媛其实很爱做饭\n",
      "lands\n",
      "spent\n",
      "train\n",
      "world\n",
      "文章来源\n",
      "在节目环节中\n",
      "于将于今晚\n",
      "core\n",
      "于年初为老公黄晓明诞下\n",
      "港星陈冠希1月被爆与女友秦舒培已经有爱的结晶\n",
      "other\n",
      "修杰楷表示\n",
      "张译让剧组女生下跪\n",
      "邓紫棋和白衣男子牵手逛街\n",
      "据网友拍摄的照片来看\n",
      "还逼迫女生下跪加入自己的帮会\n",
      "donut\n",
      "唐禹哲20日也亲自出面\n",
      "王健林近日在接受英国\n",
      "疑似自行ps合成\n",
      "magnified\n",
      "constellation\n",
      "inside\n",
      "一次过清还所有欠款\n",
      "may\n",
      "他接受访问时自曝二人都是他的女神\n",
      "nebula\n",
      "82万元\n",
      "陈数等领衔主演的古装玄幻大剧\n",
      "等好莱坞大片把一整个月占得满满当当\n",
      "白百何身边还站着一个小男孩\n",
      "神色如常地玩手机\n",
      "王健林\n",
      "forming\n",
      "2017\n",
      "李晨在某综艺节目中谈及对孩子的看法\n",
      "jets\n",
      "由鹿晗\n",
      "我是一家电影公司的商人\n",
      "之前她就带着\n",
      "有网友拍到白百何带儿子现身上海大悦城\n",
      "galaxy\n",
      "父亲节将至\n",
      "玄反影\n",
      "秦先生只有一小时玩游戏\n",
      "six\n",
      "hours\n",
      "他回说\n",
      "conception\n",
      "下一秒突然就一阵摇晃\n",
      "向西里_cili喊话\n",
      "而且预产期\n",
      "中求生存\n",
      "享年56岁\n",
      "杨丽萍与村民们\n",
      "亮相自己有份参加的真人秀\n",
      "spitzer\n",
      "约合人民币3\n",
      "出席活动\n",
      "周杰伦的音乐才华我们已经不用多说\n",
      "送给80岁的谢贤\n",
      "奔跑吧兄弟\n",
      "华人之光\n",
      "高晓松在京出席某地图发布会\n",
      "是代表香港的女神\n",
      "airbus\n",
      "除了几位工作人员的陪伴\n",
      "december\n",
      "这张照片随后被方媛秒删\n",
      "与同场的女星钟楚红及关之琳合照\n",
      "1995\n",
      "fire\n",
      "暑期档正式开启第一波鏖战\n",
      "李晨坦言自己父母离异\n",
      "土地注\n",
      "way\n",
      "应该都是郭富城爱吃的\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "getTopWords(ny, sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
